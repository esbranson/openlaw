#! /usr/bin/python3 -uW all
# -*- coding: utf-8 -*-

usage="""Usage: akncat [OPTION]... [FILE]...
Concatenate Akoma Ntoso FILE(s) sections to standard output.

With no FILE, or when FILE is -, read standard input.

  -a, --abbr         toggle output of document abbreviation (default: yes)
  -n, --nums         toggle output of section numbers (default: yes)
  -t, --headings     toggle output of title/heading/subheading (default: yes)
  -c, --content      toggle output of section content (default: yes)
  -r, --refs         toggle output of section references (default: no)
  -s, --status       toggle output of sections with statusType "removed" (default: no)
  -v, --verbose      increase verbosity
  -h, --help         display this help and exit

Examples:
  curl -fL --no-progress-meter \\
    'https://www.govinfo.gov/link/bills/117/hr/1319?billversion=mostrecent&link-type=uslm' | \\
    akncat -anc

  curl -fL --no-progress-meter \\
    'https://www.govinfo.gov/link/plaw/117/public/2?link-type=uslm' | \\
    akncat -anc

  curl -fL --no-progress-meter \\
    https://www.govinfo.gov/content/pkg/COMPS-16472/uslm/COMPS-16472.xml | \\
    akncat -anc
"""

import sys
import getopt
import logging
import os
import re
# XXX lxml is required!
try: import lxml.etree as etree
except ImportError: import xml.etree.ElementTree as etree

xmlns = "http://docs.oasis-open.org/legaldocml/ns/akn/3.0"
uslm_ns = "http://schemas.gpo.gov/xml/uslm"
ns = {'uslm': uslm_ns}

do_repealed = False
do_abbr = False
do_number = True
do_heading = True
do_content = True
do_notes = False

##
# Entry function. Parse parameters, call cat_file().
#
def main():
	global do_repealed
	global do_abbr
	global do_number
	global do_heading
	global do_content
	global do_notes
	debug = logging.WARN
	logging.basicConfig(format='akncat: {message}', style='{', level=debug)
	try:
		opts, args = getopt.getopt(sys.argv[1:], 'trncashv')
	except getopt.GetoptError as e:
		logging.fatal(f'getopt error: {e}')
		print(usage)
		sys.exit(2)
	for opt, arg in opts:
		if opt in {'-t', '--headings'}:
			do_heading = not do_heading
		elif opt in {'-r', '--refs'}:
			do_notes = not do_notes
		elif opt in {'-n', '--nums'}:
			do_number = not do_number
		elif opt in {'-c', '--content'}:
			do_content = not do_content
		elif opt in {'-a', '--abbr'}:
			do_abbr = not do_abbr
		elif opt in {'-s', '--status'}:
			do_repealed = not do_repealed
		elif opt in {'-v', '--verbose'}:
			debug -= 10
			logging.getLogger().setLevel(debug)
		elif opt in {'-h', '--help'}:
			print(usage)
			sys.exit(1)
	if len(args) < 1:
		cat_file(sys.stdin)
	else:
		for arg in args:
			cat_file(arg)
	os.close(sys.stdout.fileno())

def cat_file(path):
	if path == '-':
		path = sys.stdin
	try:
		tree = etree.parse(path)
		if tree.getroot().nsmap[None] == xmlns:
			parse_akoma_ntoso(tree)
		elif tree.getroot().nsmap[None] ==  uslm_ns:
			parse_uslm(tree)
	except (BrokenPipeError,KeyboardInterrupt):
		pass
	except etree.ParseError:
		if path is sys.stdin:
			path = '-'
		logging.info(f"Failed to parse {path}")

##
# Parse a USLM ElementTree.
#
# TODO What is the algorithm here?
# TODO Should we be editing the in-memory representation?
#
def parse_uslm(tree):
	for bad in tree.xpath("//*[self::uslm:elided]", namespaces=ns):
		remove_node(bad)

	for section in tree.xpath('//uslm:section[not(ancestor::uslm:quotedContent)]', namespaces=ns):
		if do_abbr:
			# XXX We can't delete editorialNote[@role='uscRef'] until after this!
			ident = get_id(section)
			if ident:
				section.text = ident + ' ' + (section.text or '')
		if not do_content:
			for bad in section.xpath(".//*[self::uslm:content or self::uslm:chapeau or self::uslm:subsection or self::uslm:paragraph or self::uslm:continuation]", namespaces=ns):
				remove_node(bad)
		if not do_notes:
			for bad in section.xpath(".//*[self::uslm:editorialNote or self::uslm:footnote or self::uslm:sourceCredit or self::uslm:sidenote]", namespaces=ns):
				remove_node(bad)
		if not do_number:
			# TODO Should we normalize or remove descendant <num> tags?
			for bad in section.xpath("./uslm:num", namespaces=ns):
				remove_node(bad)
		if not do_heading:
			for bad in section.xpath("./uslm:heading", namespaces=ns):
				remove_node(bad)
		print(' '.join((etree.tostring(section, encoding='unicode', method='text')).split()))

# XXX Don't remove tail text!
def remove_node(element):
	element.getparent().remove(element)

##
# Get an identifier for an element, or None.
#
# From the element or its nearest ancestor, prefer its USC identifier
# over its normal identifier.
#
def get_id(element):
	while element is not None:
		for ref in element.xpath("./uslm:editorialNote[@role='uscRef']/uslm:ref/@href", namespaces=ns):
			return str(ref)
		if "identifier" in element.attrib:
			return str(element.attrib["identifier"])
		element = element.getparent()

##
# TODO
#
def parse_akoma_ntoso(tree):
	numre = '{' + xmlns + '}num'
	headingre = '{' + xmlns + '}heading'
	contentre = './/{' + xmlns + '}content/*'
	flatcontentre = './/{' + xmlns + '}content'
	metare = '{' + xmlns + '}meta'
	abbrre = '{' + xmlns + '}abbr'
	if do_repealed:
		path = '//akn:section'
	else:
		path = '//akn:section[not(contains(@status, "removed"))]'
	sections = tree.xpath(path, namespaces={'akn': xmlns})
	trans = str.maketrans('“”’\t', '""\' ', '\n')
	abbr = ''
	if do_abbr:
		el = tree.getroot()[0]
		for subel in el:
			if subel.tag != metare and len(subel) and abbrre in subel[0].attrib:
				abbr = subel[0].attrib[abbrre] + ' '
	for section in sections:
		enum = ''
		heading = ''
		content = ''
		if do_number:
			el = section.find(numre)
			if el is not None:
				enum = el.text+'. '
		if do_heading:
			el = section.find(headingre)
			if el is not None:
				heading = el.text+'. '
		if do_content:
			els = section.iterfind(contentre)
			content = ' '.join(''.join(el.itertext()).translate(trans).strip() for el in els)
			if len(content) == 0:
				els = section.iterfind(flatcontentre)
				content = ' '.join(''.join(el.itertext()).translate(trans).strip() for el in els)
		print(abbr + enum + heading + content)

if __name__ == "__main__":
	main()

